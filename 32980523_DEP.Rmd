---
title: "FIT5147 DEP S2 2022 - 32980523"
output:
  html_notebook:
    toc: yes
---

# FIT5147 \| Data Exploration Project

## Study of Airbnb User Preferences in Chile and Australia

> The objective is to provide an easy to follow framework for analysis that allows the analyst or PhD student to walk through their entire approach in a step-by-step manner with their colleagues or PhD supervisors.

> In each of the 6-steps, the researcher is to provide their code, outputs for the code, and any comments/thoughts that may help the reader interpret the approach that was taken.

## **1. Introduction**

For this study I've chosen two cities that I'm highly familiar with: **Santiago de Chile**, where I lived most of my life up until the age of 26; and **Melbourne, Australia** where I've lived for the past 7 years. Both of this cities are upwards of 5 million people and are visited by thousand of tourists every year.

As you will see in next section, the data sets are large enough to be studied on their own, but I see an opportunity to perform insightful research by comparing additional destinations in Australia such as the Northern Rivers region in New South Wales and Barwon South West in Victoria. Both of these areas are popular holiday destinations, and it would be interesting to contrast their characteristics to bigger cities in the study. As a result of this analysis, I hope the findings may be of use as a set of fundamental insights to both investors seeking to understand the short term rental markets, or for public policy makers to provide guidance on regulation or infrastructure decisions.

### 1.1 Research Question 1: Features of popularity on each city in the study

> What are some of the common features of popular listings in the cities included in the study? For example, can we see clusters of popularity in certain areas of the city that are near the CBD or near bars and restaurants?

#### Hypothesis

Popular listings in metropolitan cities are close to entertainment hubs (pubs and restaurants) and the CBD area. Smaller cities such as Hobart or Byron Bay present a similar pattern, but they also base their popularity on closeness to beaches and national parks.

Popular listings also rely on the type of amenities provided in the accommodation such as wi-fi, number of bathrooms, etc.

#### Potential Issues or Challenges

It's possible that each listing's popularity may be based on specific qualitative characteristics that and that are problematic to measure. For example, it would be difficult to incorporate the 'word of mouth' impact of Airbnb users picking one area over another one, or to measure how many customers pick a listing for random reasons such as convenience to them specifically (i.e. listing close to a relative).

### 1.2 Research Question 2: Common features of popular listings across cities in the study

> Are there any significant differences on these features across Santiago and Melbourne suburbs? For example, are the popular areas in Santiago more concentrated compared to Melbourne?

#### Hypothesis

Melbourne and Santiago are unlike each other in many respects. Melbourne's suburbs are reasonably self-contained with amenities and entertainment in walking distance, while Santiago is a more spread out city with less number of hubs per suburb. Therefore, more clusters of popularity would be expected to be seen in Santiago than Melbourne.

On the other hand, there should be evidence around popular listing characteristics that are independent of location.

#### Potential Issues or Challenges

Comparing cities that are vastly different in demographics could introduce noise into the results...

### 1.3 Research Question 3: How have the listing prices evolved during the last year across all cities in the study?

#### Hypothesis

It's expected that all listing prices have increased in the time frame of this project (2 years). In particular, the pandemic may have had a significant impact of prices on cities such as Hobart and in the Northern Rivers as people fled into towns with less restrictions. The opposite would be expected for Santiago and Melbourne.

#### Potential Issues or Challenges

some text

### 1.4 Environment Setup

The following packages will be used for this project:

| Package name | Category               |
|--------------|------------------------|
| `tidyverse`  | General Data Analysis  |
| `dplyr`      | General data analysis  |
| `broom`      | Geo-spatial Analysis   |
| `ggmap`      | Geo-spatial Analysis   |
| `mapproj`    | Geo-spatial Analysis   |
| `geogjsonio` | Geo-spatial Analysis   |
| `ggmap`      | Geo-spatial Analysis   |
| `ggplot2`    | General visualizations |
| `janitor`    | Data Cleaning          |
| `naniar`     | Data Cleaning          |
| `UpSetR`     | Data Cleaning          |

: Selected libraries

```{r libraries, warning=FALSE, include=FALSE}

packages = c('tidyverse', 'ggplot2', 'skimr', 'naniar', 'kableExtra','dplyr', 'ggstatsplot','plotly','haven','funModeling','crosstalk','data.table', 'ggmosaic','ggExtra','ggpubr','sf','tmap','sp', 'leaflet','widgetframe','broom','geojsonio','rgdal','tmap','tmaptools','janitor','dplyr','geojsonio','ggside')

#loop to install packages
for(p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}

```

------------------------------------------------------------------------

## **2. Data Collection and Measurement Strategy (Data Wrangling - Data Checking)**

### 2.1 Description of the data

The data set contains information from [Inside Airbnb](http://insideairbnb.com/get-the-data/) about four different regions:

1.  Melbourne, Australia (best city in the world)
2.  Northern Rivers, Australia (land of Byron Bay and other wonders)
3.  Tasmania, Australia (the island of the island)
4.  Santiago, Chile (hometown of the author of this report)

We will also use *four sets* of quarterly produced data for each one of the regions, in order to explore time-wise variability of the listings.

A summary of all the information is provided in the table below:

| Dataset  | Description                                               | Total Observations | Most Relevant Fields                                                                                                                                |
|------------|------------|------------|-------------------------------------|
| Listings | Detailed listings with 74 key attributes for each listing |                    | `neighbourhood`, `latitude`, `longitude`, `room_type`, `price`, `minimum_nights`, `number_of_reviews`, `reviews_per_month`, and `availability_365.` |
| Calendar |                                                           |                    |                                                                                                                                                     |
| Reviews  |                                                           |                    |                                                                                                                                                     |

### 2.2 Data Loading

The following steps will go through loading the data that will be used throughout the project.

#### 2.2.1 Listings

Although Airbnb provides a rich data set of 74 variables for listings, most of them won't be useful for the study. More details on the selected variables will be explained in section (TBC).

```{r}
# combine data sets
all.listings <- list.files(recursive = TRUE, pattern="^listings.csv.gz$") %>%
  map_df(~read_csv(.,show_col_types = FALSE))
```

#### 2.2.2 Reviews

Intro to review information

```{r}
# combine data sets
all.reviews <- list.files(recursive = TRUE, pattern="^reviews.csv.gz$") %>%
  map_df(~read_csv(.,show_col_types = FALSE))
```

Some description about the reviews in the project

#### 2.2.3 Calendar

Intro to calendar information

```{r}
# combine data sets
# all.calendar <- list.files(recursive = TRUE, pattern="^calendar.csv.gz$") %>%
#   map_df(~read_csv(.,show_col_types = FALSE))
```

Some description about results

### 2.3 Data Cleaning

#### 2.3.1 Data Cleaning: Duplicates

-   First, we will check for duplicates on each data frame, by using `get_dupes` function from the `janitor` library:

```{r}
#check listing duplicates
listings.dupes <- get_dupes(all.listings, id, last_scraped)
```

```{r}
#check reviews duplicates
review.dupes <- get_dupes(all.reviews,-c(comments,reviewer_name))
```

```{r}
head(review.dupes)
```

```{r}
#run later
# calendar.dupes <- get_dupes(all.reviews,-c(comments,reviewer_name))
```

-   removed the duplicates reviews

```{r}
#remove duplicated reviews
# fix later
all.reviews <- all.reviews %>% distinct_at(vars(-comments,-reviewer_name))
```

#### 2.3.2 Data Cleaning: Missing Values

We will use the fantastic tools from the `naniar` summarize issues with missing values:

```{r}
all.listings %>% 
  miss_var_summary() %>% 
  filter(pct_miss >20)
```

```{r}
all.reviews %>% 
  miss_var_summary()
```

Within the `all.listings` data frame we can see that `license`, `host_neighbourhood`, `neighbourhood_group_cleansed`, `bathrooms`, and `calendar_updated` have missing values. Furthermore, this visualization tells us that all these variables have 691.141 missing values together, while smaller groupings of these variables have between 30.000 and 35.000 missing variables together.

The `all.reviews` data frame has a low rate of missing values, with 800 missing values for `comments` and 1 missing value for `reviewer_name`.

The `all.calendar` data frame has a fairly low rate of missing values, with only 1.432 values for `minimum_nights` `maximum_nights` combined, and only 953 missing values for `price` and `adjusted_price` combined.

#### 2.3.3 Data Cleaning: Preparation of new Variables

-   Remove unnecessary variables

```{r}
all.listings.clean <- all.listings %>%
  select(-listing_url, -scrape_id, -neighborhood_overview, -picture_url, -host_id, -host_url, -host_name, -host_location,
         -host_thumbnail_url, -host_picture_url, -first_review, -last_review, -calendar_last_scraped,
         -has_availability, -host_has_profile_pic, -calendar_updated, -license, -bathrooms, -neighbourhood, -host_neighbourhood, -neighbourhood_group_cleansed)
```

-   Rename names of lengthy features

```{r}
#rename some annoyingly long columns names
all.listings.clean <- all.listings.clean %>% rename(nb_cleansed = neighbourhood_cleansed)
```

-   Connect a list of neighborhood by city to the main listing data

```{r}
nb.list <- read_csv("data/neighbourhoods.csv", show_col_types = FALSE)

all.listings.clean <- all.listings.clean %>% left_join(nb.list, by=c("nb_cleansed" = "neighbourhood_cleansed"))
```

-   Correct any data type in the `all.listings` data frame that may not be fit for analysis, and at this stage it's only the `price` variable:

```{r}
#using parse_number to fix price data type
all.listings.clean$price <- parse_number(all.listings.clean$price)
```

-   And remove listings with price equal to zero or negative values (6 listings)

```{r}
all.listings.clean %>% filter(price == 0)
all.listings.clean %>% filter(price < 0)
all.listings.clean <- all.listings.clean %>% filter(price!=0)
```

-   Correct name caps

Also, some of the neighborhood names are incorrectly formatted:

```{r}
#fixing capitalised words
#check later, as it may get in the way with joins
all.listings.clean$nb_cleansed <- str_to_title(all.listings.clean$nb_cleansed)
```

-   Reformat scraped data

```{r}
# reformat scraping dates
all.listings.clean$last_scraped.new <- format(all.listings.clean$last_scraped,'%b-%Y')
```

-   Replace host_verification and amenities with count of the variables

```{r}
# replace amenities textual variable with count of amenities
all.listings.clean <- all.listings.clean %>%
  mutate(amenities_count = sapply(str_split(amenities, ","), length)) %>%
  select(-amenities)
# replace amenities textual variable with count of amenities
```

-   Create binned variable for ratings

```{r}
# 1.6 Create binned variable for ratings
all.listings.clean$rating.bin <- cut(all.listings.clean$review_scores_rating, c(0,1,2,3,4,5))
```

-   Improve property type variable

```{r}
# get actual property type (remove room type component) from property_type
all.listings.clean <- all.listings.clean %>%
  mutate(property_type = tolower(property_type)) %>%
  mutate(property_type = case_when(
    grepl(" in ", property_type, fixed = TRUE) == TRUE ~ gsub("^.*in ", "", property_type),
    TRUE ~ gsub("entire ", "", property_type)
  ))
```

-   Finally, factorize all character and logical variables for later processing.

```{r}
all.listings.final <- all.listings.clean %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(across(where(is.logical), as.factor))
```

#### 2.3.4 Findings

-   duplicate calendar items

-   duplicate reviews

-   Clearly walk through the data cleaning process.

-   Is any data missing, if so how much?

-   Describe any imputation process for missing data.

-   If any data was removed prior to analysis explain why.

## **Step 3: Visualize & Summarize Data**

Once data has been collected and cleaned, provide an overview of the data using summarize statistics and visuals.

### 3.1 Univariate Analysis

```{r}
# need to filter out data in 2 ways
# only use latest quarter
#filter out better columns for analysis.

hist1 <- ggplot(data=all.listings.final
                ,aes(x=log10(price), fill=nb_group))+
   geom_histogram(position = "identity", alpha = 0.2, bins = 50)
hist1
```

```{r}
#melbourne
ggplot(data = all.listings.final %>% 
         group_by(nb_group,nb_cleansed,rating.bin) %>%
         filter(nb_group =="Melbourne") %>% 
         filter(rating.bin!= "NA") %>% 
         tally() %>% 
         rename(total.listings = n),
       aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + 
  coord_flip() +
  labs(x="Neighbourhood", y="Count of Listings")
#santiago
ggplot(data = all.listings.final %>% 
         group_by(nb_group,nb_cleansed,rating.bin) %>%
         filter(nb_group =="Santiago") %>% 
         filter(rating.bin!= "NA") %>% 
         tally() %>% 
         rename(total.listings = n),
       aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity")+
  coord_flip() +
  labs(x="Neighbourhood", y="Count of Listings")
  
#northern rivers
ggplot(data = all.listings.final %>% 
         group_by(nb_group,nb_cleansed,rating.bin) %>%
         filter(nb_group =="Northern Rivers") %>%
         filter(rating.bin!= "NA") %>% 
         tally() %>% 
         rename(total.listings = n),
       aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + 
  coord_flip() +
  labs(x="Neighbourhood", y="Count of Listings")
#tassie
ggplot(data = all.listings.final %>% 
         group_by(nb_group,nb_cleansed,rating.bin) %>%
         filter(nb_group =="Tasmania") %>%
         filter(rating.bin!= "NA") %>% 
         tally() %>% 
         rename(total.listings = n),
       aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + 
  coord_flip() +
  labs(x="Neighbourhood", y="Count of Listings")
```

```{r}
ggplot(userData, aes(month, count, fill = count)) +
    geom_bar(stat = "identity") +
    scale_x_date() + 
    scale_fill_continuous(low="blue", high="red") +
    labs(x= "Time", y="Count")
ggplot(data = all.listings.final %>% 
         group_by(nb_group,nb_cleansed,rating.bin) %>%
         filter(nb_group =="Melbourne") %>% 
         filter(rating.bin!= "NA") %>% 
         tally() %>% 
         rename(total.listings = n),
       aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + 
  coord_flip()
```

### 3.2 Bivariate Analysis

Firstly, we will use a scatter plot

```{r}
scat1 <- ggplot(all.listings.final %>%
          filter(last_scraped.new=="Jun-2022") %>%
          select(nb_group,nb_cleansed,review_scores_rating,amenities_count, host_is_superhost), 
             aes(review_scores_rating,amenities_count, colour = nb_group)) +
               geom_point()
  
scat2<- ggMarginal(scat1, groupColour = TRUE, groupFill = TRUE)
scat2
```

```{r}
#filter data to last quarter
# 
scat3 <- ggplot(all.listings.final %>%
          filter(last_scraped.new=="Jun-2022") %>%
          filter(review_scores_rating>4) %>% 
          select(nb_group,nb_cleansed,review_scores_rating,amenities_count, host_is_superhost), 
             aes(review_scores_rating,amenities_count, colour = nb_group)) +
               geom_point()
  
scat4<- ggMarginal(scat3, groupColour = TRUE, groupFill = TRUE)
scat4
```

Histograms by group

### 3.3 Mapping

Lets visualize the listing ratings by city. Firstly, we will visualize a clustered representation of the listings with leaflet to help set the lay of the land across all cities.

#### Melbourne

```{r echo=FALSE}
#Reading Listings Data
#load data frame (filtered by city)
listings.mel <- all.listings.final %>% 
  filter(last_scraped == "2022-06-06") %>% 
  filter(nb_group == "Melbourne")

#Creating Listings across N
leaflet(listings.mel) %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,labelOptions = labelOptions(noHide = F),clusterOptions = markerClusterOptions(),popup = paste0("<b> Listing name: </b>", listings.mel$name , "<br/><b> Host Name: </b>", listings.mel$host_name, "<br> <b> Price: </b>", listings.mel$price, "<br/><b> Room Type: </b>", listings.mel$room_type, "<br/><b> Property Type: </b>", listings.mel$property_type
                 )) %>% 
  setView(144.94,-37.84, zoom = 12)
```

```{r message=FALSE, warning=FALSE}
# load melbourne map
mel.map <- st_read("data/Melbourne/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)

# collapse dataframe and summarise price by neighbourhood
listing_summary <- all.listings.final %>%
  filter(last_scraped.new == "Jun-2022") %>% 
  group_by(nb_group,nb_cleansed,last_scraped.new) %>%
  summarise(count = n(),
            avg_price = mean(price),
            min_price = min(price),
            max_price = max(price))

#correct listing summary fields

listing_summary$nb_cleansed <- as.character(listing_summary$nb_cleansed)
listing_summary <- listing_summary %>% rename(neighbourhood = nb_cleansed)

# combine summary and map
mel.map.data <- mel.map %>% inner_join(listing_summary)

#plot map
ggplot(mel.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

Bar plot based on neighborhood

```{r}
grouped.mel <- listings.mel %>%
  group_by(neighbourhood_cleansed,rating.bin) %>%
  tally() %>%
  rename(total.listings = n)
#plot it
ggplot(grouped.mel, aes(x = reorder(neighbourhood_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + coord_flip()
```

One clear issue is that there's a disproportionate number of 4-5 star reviews in the data set, which

#### Santiago

```{r echo=FALSE}
#Reading Listings Data
#load data frame (filtered by city)
listings.scl <- all.listings.final %>% 
  filter(last_scraped == "2022-06-22") %>% 
  filter(nb_group == "Santiago")

#Creating Listings across N
leaflet(listings.scl) %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,labelOptions = labelOptions(noHide = F),clusterOptions = markerClusterOptions(),popup = paste0("<b> Listing name: </b>", listings.scl$name , "<br/><b> Host Name: </b>", listings.scl$host_name, "<br> <b> Price: </b>", listings.scl$price, "<br/><b> Room Type: </b>", listings.scl$room_type, "<br/><b> Property Type: </b>", listings.scl$property_type
                 )) %>% 
  setView(-70.645348,-33.459229, zoom = 12)
```

```{r}
# load melbourne map
scl.map <- st_read("data/Santiago/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)

# collapse dataframe and summarise price by neighbourhood
listing_summary.scl <- all.listings.final %>%
  filter(last_scraped.new == "Jun-2022", nb_group == "Santiago") %>% 
  group_by(nb_group,nb_cleansed,last_scraped.new) %>%
  summarise(count = n(),
            avg_price = mean(price),
            min_price = min(price),
            max_price = max(price))

#correct listing summary fields

listing_summarys.scl$nb_cleansed <- as.character(listing_summary$nb_cleansed)
listing_summary <- listing_summary %>% rename(neighbourhood = nb_cleansed)

# combine summary and map
mel.map.data <- mel.map %>% inner_join(listing_summary)

#plot map
ggplot(mel.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

```{r}
grouped.scl <- listings.scl %>%
  group_by(nb_cleansed,rating.bin) %>%
  tally() %>%
  rename(total.listings = n)
#plot it
ggplot(grouped.scl, aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + coord_flip()
```

#### Northern Rivers

```{r echo=FALSE}
#Reading Listings Data
#load data frame (filtered by city)
listings.nr <- all.listings %>% 
  filter(last_scraped == "2022-06-11") %>% 
  filter(neighbourhood_group.new == "Northern Rivers")

#Creating Listings across N
leaflet(listings.nr) %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,labelOptions = labelOptions(noHide = F),clusterOptions = markerClusterOptions(),popup = paste0("<b> Listing name: </b>", listings.nr$name , "<br/><b> Host Name: </b>", listings.nr$host_name, "<br> <b> Price: </b>", listings.nr$price, "<br/><b> Room Type: </b>", listings.nr$room_type, "<br/><b> Property Type: </b>", listings.nr$property_type
                 )) %>% 
  setView(153.6,-28.6, zoom = 8)
```

```{r}
grouped.nr <- listings.nr %>%
  group_by(nb_cleansed,rating.bin) %>%
  tally() %>%
  rename(total.listings = n)
#plot it
ggplot(grouped.nr, aes(x = reorder(nb_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + coord_flip()
```

#### Tasmania

```{r echo=FALSE}
#Reading Listings Data
#load data frame (filtered by city)
listings.tas <- all.listings %>% 
  filter(last_scraped == "2022-06-05") %>% 
  filter(neighbourhood_group.new == "Tasmania")

#Creating Listings across N
leaflet(listings.tas) %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,labelOptions = labelOptions(noHide = F),clusterOptions = markerClusterOptions(),popup = paste0("<b> Listing name: </b>", listings.tas$name , "<br/><b> Host Name: </b>", listings.tas$host_name, "<br> <b> Price: </b>", listings.tas$price, "<br/><b> Room Type: </b>", listings.tas$room_type, "<br/><b> Property Type: </b>", listings.tas$property_type
                 )) %>% 
  setView(146.8,-41.5, zoom = 7)
```

```{r}
grouped.tas <- listings.tas %>%
  group_by(neighbourhood_cleansed,rating.bin) %>%
  tally() %>%
  rename(total.listings = n)
#plot it
ggplot(grouped.tas, aes(x = reorder(neighbourhood_cleansed, total.listings), y = total.listings)) + geom_bar(mapping = aes(fill= rating.bin),stat="identity") + coord_flip()
```

Next, we will perform uni variate analysis over some key data sets

**Popularity clusters (ggplot chorophlet of colored ratings)**

```{r}
#turn off sci notation.
options(scipen = 999)
# loading map geojson file
mel.map <- st_read("data/Melbourne/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)
# create inner join of map and listings data
map.plus.listings.mel <- mel.map %>% 
  inner_join(grouped.mel, by = c("neighbourhood" = "neighbourhood_cleansed"))

```

**Ratings vs count of amenities per listing (per city zone)**

**Popularity and closeness to CBD (Santiago Melbourne**

Perhaps prices are a good indicator of indicator of preference?

```{r message=FALSE, warning=FALSE, include=FALSE}
options(scipen=999)

# load melbourne map
mel.map <- st_read("data/Melbourne/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)
#load scl map
scl.map <- st_read("data/Santiago/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)
#load tassie map
tas.map <- st_read("data/Tasmania/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)
#load nr map
nr.map <- st_read("data/Northern Rivers/2022_06/neighbourhoods.geojson", stringsAsFactors = FALSE)
nr.map$neighbourhood <- str_to_title(nr.map$neighbourhood)


# collapse dataframe and summarise price by neighbourhood
listing_summary <- all.listings.final %>%
  filter(last_scraped.new == "Jun-2022") %>% 
  group_by(nb_group,nb_cleansed,last_scraped.new) %>%
  summarise(count = n(),
            avg_price = mean(price),
            min_price = min(price),
            max_price = max(price))

#correct listing summary fields

listing_summary$nb_cleansed <- as.character(listing_summary$nb_cleansed)
listing_summary <- listing_summary %>% rename(neighbourhood = nb_cleansed)

# combine summary and map
mel.map.data <- mel.map %>% inner_join(listing_summary)
scl.map.data <- scl.map %>% inner_join(listing_summary)
tas.map.data <- tas.map %>% inner_join(listing_summary)
nr.map.data <- nr.map %>% inner_join(listing_summary)
```

```{r}

#plot maps
ggplot(mel.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

```{r}
#
ggplot(scl.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

```{r}

ggplot(tas.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

```{r}
ggplot(nr.map.data) +
  geom_sf(aes(fill=avg_price)) +
  scale_fill_gradient(low = "#56B1F7", high ="#132B43") +
  geom_sf_text(aes(label=neighbourhood),color="white", check_overlap = TRUE)
```

However, this is

Hypothesis 1:

Popular listings in metropolitan cities are close to entertainment hubs (pubs and restaurants) and the CBD area. Smaller cities such as Hobart or Byron Bay present a similar pattern, but they also base their popularity on closeness to beaches and national parks.

Popular listings also rely on the type of amenities provided in the accommodation such as wi-fi, number of bathrooms, etc.

### Calendar

### Reviews

-   Offer interpretation of visuals that may help guide the model building process or generate discussion about any underlying trends in the data specific to the research question.

## **Step 6: Communication of Results**

-   Communicate the results of the final model(s) in a clear manner using visualizations and language that is understandable to the end user.

-   Explain whether or not the research question has been answered.

-   Clearly discuss any limitations of the analysis.

-   Offer suggestions for future analysis or perhaps other data sets that may be incorporated to provide a more contextual answer to the research question.

------------------------------------------------------------------------

## References

[1] [Plot polygons from GeoJSON file to leaflet map](https://www.youtube.com/watch?v=hGzlvSIhvIc) (maps)

[2] [pw2/Data-Analysis-Framework: Step-by-step template for analysis/research projects (github.com)](https://github.com/pw2/Data-Analysis-Framework/tree/master) (report format)

[3] [How to clean the datasets in R? \| R-bloggers](https://www.r-bloggers.com/2021/04/how-to-clean-the-datasets-in-r/) (data cleaning)

[4][Data Structures, Summaries, and Visualisations for Missing Data â€¢ naniar (njtierney.com)](<https://naniar.njtierney.com/>) (naniar)
